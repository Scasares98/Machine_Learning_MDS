Autor: Sergio Casares Fernández

Descenso del Gradiente:

https://es.wikipedia.org/wiki/Regresi%C3%B3n_log%C3%ADstica
https://www.ellaberintodefalken.com/2019/03/regresion-lineal-descenso-de-gradiente.html
https://www.ellaberintodefalken.com/2019/03/regresion-lineal-descenso-de-gradiente.html
https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd
Función Sigmoide:

https://es.wikipedia.org/wiki/Funci%C3%B3n_sigmoide
Función np.dot:

https://numpy.org/doc/stable/reference/generated/numpy.dot.html
Repositorios Github:

https://github.com/Arko98/Gradient-Descent-Algorithms/tree/master/Algorithms
https://github.com/Benlau93/Machine-Learning-by-Andrew-Ng-in-Python
Squared Error:

https://datascience.stackexchange.com/questions/10188/why-do-cost-functions-use-the-square-error